{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T07:03:48.100441Z",
     "start_time": "2024-04-20T07:03:47.982772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Apr 25 10:48:34 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 552.22                 Driver Version: 552.22         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...  WDDM  |   00000000:01:00.0 Off |                  N/A |\n",
      "|  0%   33C    P8              3W /  220W |     700MiB /  12282MiB |     26%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      2188    C+G   ...64__8wekyb3d8bbwe\\CalculatorApp.exe      N/A      |\n",
      "|    0   N/A  N/A      5776    C+G   C:\\Windows\\System32\\WUDFHost.exe            N/A      |\n",
      "|    0   N/A  N/A      5980    C+G   ...B\\system_tray\\lghub_system_tray.exe      N/A      |\n",
      "|    0   N/A  N/A      7208    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A      8340    C+G   C:\\Windows\\System32\\dwm.exe                 N/A      |\n",
      "|    0   N/A  N/A     11352    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     11364    C+G   ...al\\Discord\\app-1.0.9042\\Discord.exe      N/A      |\n",
      "|    0   N/A  N/A     11592    C+G   ..._8wekyb3d8bbwe\\PaintStudio.View.exe      N/A      |\n",
      "|    0   N/A  N/A     11896    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     12748    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13316    C+G   ...ekyb3d8bbwe\\PhoneExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     13508    C+G   ....Search_cw5n1h2txyewy\\SearchApp.exe      N/A      |\n",
      "|    0   N/A  N/A     13888    C+G   ...on\\123.0.2420.97\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     14592    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     14984    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16032      C   ...vVirtualCamera\\NVIDIA Broadcast.exe      N/A      |\n",
      "|    0   N/A  N/A     16748    C+G   ...s\\TeamViewer\\TeamViewer_Desktop.exe      N/A      |\n",
      "|    0   N/A  N/A     20816    C+G   ...GeForce Experience\\NVIDIA Share.exe      N/A      |\n",
      "|    0   N/A  N/A     21500    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717f09d1c1ba9038",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-20T07:10:56.964384Z",
     "start_time": "2024-04-20T07:10:01.931829Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install -q autotrain-advanced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519bb54569fc338d",
   "metadata": {},
   "source": [
    "PyTorch 업데이트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f526db6344b1b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-25 10:50:18\u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mInstalling latest xformers\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-25 10:50:19\u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mSuccessfully installed latest xformers\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-25 10:50:19\u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mInstalling latest PyTorch\u001b[0m\n",
      "\u001b[1mINFO    \u001b[0m | \u001b[32m2024-04-25 10:51:46\u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m53\u001b[0m - \u001b[1mSuccessfully installed latest PyTorch\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!autotrain setup --update-torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66dfc3aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.43.1-py3-none-win_amd64.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: torch in c:\\workspace\\ai\\korquad-withgpt\\quadvenv\\lib\\site-packages (from bitsandbytes) (2.3.0+cu121)\n",
      "Requirement already satisfied: numpy in c:\\workspace\\ai\\korquad-withgpt\\quadvenv\\lib\\site-packages (from bitsandbytes) (1.26.4)\n",
      "Requirement already satisfied: filelock in c:\\workspace\\ai\\korquad-withgpt\\quadvenv\\lib\\site-packages (from torch->bitsandbytes) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\workspace\\ai\\korquad-withgpt\\quadvenv\\lib\\site-packages (from torch->bitsandbytes) (4.11.0)\n",
      "Requirement already satisfied: sympy in c:\\workspace\\ai\\korquad-withgpt\\quadvenv\\lib\\site-packages (from torch->bitsandbytes) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\workspace\\ai\\korquad-withgpt\\quadvenv\\lib\\site-packages (from torch->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\workspace\\ai\\korquad-withgpt\\quadvenv\\lib\\site-packages (from torch->bitsandbytes) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\workspace\\ai\\korquad-withgpt\\quadvenv\\lib\\site-packages (from torch->bitsandbytes) (2024.3.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\workspace\\ai\\korquad-withgpt\\quadvenv\\lib\\site-packages (from torch->bitsandbytes) (2021.4.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\workspace\\ai\\korquad-withgpt\\quadvenv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->bitsandbytes) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\workspace\\ai\\korquad-withgpt\\quadvenv\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch->bitsandbytes) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\workspace\\ai\\korquad-withgpt\\quadvenv\\lib\\site-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\workspace\\ai\\korquad-withgpt\\quadvenv\\lib\\site-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
      "Downloading bitsandbytes-0.43.1-py3-none-win_amd64.whl (101.6 MB)\n",
      "   ---------------------------------------- 0.0/101.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/101.6 MB 1.7 MB/s eta 0:01:02\n",
      "   ---------------------------------------- 0.5/101.6 MB 6.7 MB/s eta 0:00:16\n",
      "   ---------------------------------------- 1.2/101.6 MB 9.9 MB/s eta 0:00:11\n",
      "    --------------------------------------- 2.3/101.6 MB 14.5 MB/s eta 0:00:07\n",
      "    --------------------------------------- 2.4/101.6 MB 11.0 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 2.8/101.6 MB 11.1 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 3.2/101.6 MB 11.4 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 3.3/101.6 MB 9.6 MB/s eta 0:00:11\n",
      "   - -------------------------------------- 3.5/101.6 MB 8.8 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 3.8/101.6 MB 8.6 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 4.7/101.6 MB 9.7 MB/s eta 0:00:10\n",
      "   -- ------------------------------------- 6.7/101.6 MB 12.7 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 9.4/101.6 MB 16.2 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 9.6/101.6 MB 15.8 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 9.6/101.6 MB 14.7 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 9.7/101.6 MB 13.8 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 9.9/101.6 MB 12.9 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 10.2/101.6 MB 12.6 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 10.5/101.6 MB 12.8 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 10.7/101.6 MB 12.4 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 10.8/101.6 MB 11.9 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 11.1/101.6 MB 11.3 MB/s eta 0:00:09\n",
      "   ---- ----------------------------------- 12.2/101.6 MB 11.5 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 14.5/101.6 MB 16.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 17.4/101.6 MB 17.3 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 19.6/101.6 MB 17.2 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 22.0/101.6 MB 50.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 24.3/101.6 MB 54.7 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 26.7/101.6 MB 50.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 29.4/101.6 MB 54.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 32.1/101.6 MB 54.7 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 33.9/101.6 MB 54.4 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 36.7/101.6 MB 54.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 39.4/101.6 MB 54.4 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 42.3/101.6 MB 54.4 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 45.0/101.6 MB 59.8 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 47.7/101.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 50.4/101.6 MB 59.5 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 53.2/101.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 55.9/101.6 MB 59.5 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 57.9/101.6 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 58.0/101.6 MB 46.7 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 58.5/101.6 MB 38.5 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 59.6/101.6 MB 34.6 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 62.2/101.6 MB 34.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 64.1/101.6 MB 32.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 66.8/101.6 MB 32.8 MB/s eta 0:00:02\n",
      "   --------------------------- ------------ 69.6/101.6 MB 54.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 72.0/101.6 MB 50.4 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 73.5/101.6 MB 54.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 73.6/101.6 MB 43.7 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 73.9/101.6 MB 36.4 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 74.4/101.6 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 77.2/101.6 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 79.9/101.6 MB 31.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 82.7/101.6 MB 32.8 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 84.0/101.6 MB 46.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 84.2/101.6 MB 38.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 84.4/101.6 MB 36.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 86.0/101.6 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 87.0/101.6 MB 31.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 89.7/101.6 MB 31.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 90.4/101.6 MB 28.5 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 90.6/101.6 MB 25.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 90.9/101.6 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 92.9/101.6 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 95.6/101.6 MB 31.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 98.3/101.6 MB 32.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.7/101.6 MB 32.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  99.9/101.6 MB 28.5 MB/s eta 0:00:01\n",
      "   --------------------------------------  100.0/101.6 MB 25.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  100.4/101.6 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  101.6/101.6 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  101.6/101.6 MB 29.7 MB/s eta 0:00:01\n",
      "   --------------------------------------- 101.6/101.6 MB 24.2 MB/s eta 0:00:00\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.43.1\n"
     ]
    }
   ],
   "source": [
    "!pip install bitsandbytes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a0a9574325dbde",
   "metadata": {},
   "source": [
    "Korquad 데이터셋에 맞게 Llama2 Fine-Tuning\n",
    "autotrain 설정값: https://github.com/huggingface/autotrain-advanced/blob/f1367b590dfc53d240e9684779991da540590386/src/autotrain/cli/run_llm.py#L21 (과거 버전[0.6.35])\n",
    "autotrain 설정값: https://github.com/huggingface/autotrain-advanced/blob/main/src/autotrain/cli/run_llm.py#L17 (최신 버전[0.6.80])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9a4f8591afc7c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation 적용 x\n",
    "# !autotrain llm --train \\\n",
    "#     --project_name \"llama2-korquad-finetuning\" \\\n",
    "#     --model \"TinyPixel/Llama-2-7B-bf16-sharded\" \\\n",
    "#     --data_path \"korquad_prompt\" \\\n",
    "#     --text_column \"text\" \\\n",
    "#     --use_peft \\\n",
    "#     --use_int4 \\\n",
    "#     --learning_rate 2e-4 \\\n",
    "#     --train_batch_size 4 \\\n",
    "#     --num_train_epochs 100 \\\n",
    "#     --trainer sft \\\n",
    "#     --model_max_length 256\n",
    "# Data Augmentation 적용 o (과거 버전)[0.6.35]\n",
    "# !autotrain llm --train \\\n",
    "#     --project_name \"llama2-korquad-finetuning-da\" \\\n",
    "#     --model \"TinyPixel/Llama-2-7B-bf16-sharded\" \\\n",
    "#     --data_path \"korquad_prompt_da\" \\\n",
    "#     --text_column \"text\" \\\n",
    "#     --use_peft \\\n",
    "#     --use_int4 \\\n",
    "#     --learning_rate 2e-4 \\\n",
    "#     --train_batch_size 8 \\\n",
    "#     --num_train_epochs 40 \\\n",
    "#     --trainer sft \\\n",
    "#     --model_max_length 256\n",
    "# Data Augmentation 적용 o (최신 버전)[0.6.80]\n",
    "\n",
    "!autotrain llm --train \\\n",
    "    --project-name \"llama2-korquad-finetuning\" \\\n",
    "    --model \"hyunseoki/ko-ref-llama2-7b\" \\\n",
    "    --data-path \"seoma/korquad2-dev\" \\\n",
    "    --text-column \"text\" \\\n",
    "    --peft \\\n",
    "    --quantization \"int4\" \\\n",
    "    --lr 2e-4 \\\n",
    "    --batch-size 16 \\\n",
    "    --epochs 40 \\\n",
    "    --trainer sft \\\n",
    "    --model_max_length 256\n",
    "\n",
    "\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "# 압축할 폴더 이름\n",
    "folder_name = \"llama2-korquad-finetuning\"\n",
    "\n",
    "# 생성될 ZIP 파일 이름\n",
    "zip_file_name = \"llama2-korquad-finetuning.zip\"\n",
    "\n",
    "# 폴더를 ZIP 파일로 압축\n",
    "shutil.make_archive(zip_file_name[:-4], 'zip', folder_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
